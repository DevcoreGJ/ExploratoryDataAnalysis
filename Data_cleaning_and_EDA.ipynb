{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Python imports"
      ],
      "metadata": {
        "id": "afkKIbGyhvNb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bA4E6z-2Y0eD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#datasource"
      ],
      "metadata": {
        "id": "OjISubTKh2QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the CSV file into a numpy array\n",
        "data = pd.read_csv('raw_house_data.csv', header=None)"
      ],
      "metadata": {
        "id": "U51_0psgZx3_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Column names"
      ],
      "metadata": {
        "id": "wDflTt7mr2J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the columns of the dataframe\n",
        "data.columns = ['MLS', 'sold_price', 'zipcode', 'longitude', 'latitude', 'lot_acres', 'taxes', \n",
        "                'year_built', 'bedrooms', 'bathrooms', 'sqrt_ft', 'garage', 'kitchen_features', \n",
        "                'fireplaces', 'floor_covering', 'HOA']"
      ],
      "metadata": {
        "id": "FvQUncDOr9vH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the data array to verify that it loaded correctly\n",
        "print(\"Data shape:\", data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z9CJF7caimd",
        "outputId": "f82ea54b-cd8a-4faf-f297-b12106185d68"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (5001, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Data_Shape: (5001, 16) output says that the data has a shape of 5001 rows and 16 columns.\n",
        "\n",
        "What this means in we have 5001 data points and for 1 data point we have 16 features."
      ],
      "metadata": {
        "id": "d9WcxZuJfow8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The steps to preprocessing the data"
      ],
      "metadata": {
        "id": "f3Od3LWQkjBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the data is loaded in and we understand it's shape, it is time to understand preprocessing. Preprocessing a dataset refers to techniques and methods. The steps are:\n",
        "- Cleaning the data\n",
        "- handling missing values\n",
        "- transforming data for increased suitability for modelling\n",
        "- and either scaling or normalizing the data."
      ],
      "metadata": {
        "id": "GBbgyFBigzhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning the data"
      ],
      "metadata": {
        "id": "pVMB1sUfhqjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use the dropna() method to remove any rows with null values. The resulting DataFrame with null values removed is stored in data_clean. We use the drop_duplicates() method to get rid of any duplicate rows from the dataframe I stuck them together because I didn't want to unneccesarily have a different variable for clean and dropdupes.\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "a05e2CfajTiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with any null values and drop duplicates\n",
        "data_clean = data.dropna().drop_duplicates()\n",
        "\n",
        "# Print the shape of the cleaned data\n",
        "print(\"Cleaned Data shape:\", data_clean.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qtmP_sIfwGm",
        "outputId": "72bdb1f8-ba37-409e-f0c5-cecdd0219359"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Data shape: (4974, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AN3IPAIqlEEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##visualization"
      ],
      "metadata": {
        "id": "UjQmqZh-mtzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a good chance due to using data_clean that the first column of my dataframe is 'data_clean' however in class we have been using the mathematical notation to retrieve column 0."
      ],
      "metadata": {
        "id": "Oy-ZEesmn-_n"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tOHZy3tKsOlM"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}