{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Python imports"
      ],
      "metadata": {
        "id": "afkKIbGyhvNb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bA4E6z-2Y0eD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#datasource"
      ],
      "metadata": {
        "id": "OjISubTKh2QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from the CSV file into a numpy array\n",
        "data = pd.read_csv('raw_house_data.csv', header=None)"
      ],
      "metadata": {
        "id": "U51_0psgZx3_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the data array to verify that it loaded correctly\n",
        "print(\"Data shape:\", data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z9CJF7caimd",
        "outputId": "1f5d237b-5953-44e9-816e-fc220db553b6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (5001, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Data_Shape: (5001, 16) output says that the data has a shape of 5001 rows and 16 columns.\n",
        "\n",
        "What this means in we have 5001 data points and for 1 data point we have 16 features."
      ],
      "metadata": {
        "id": "d9WcxZuJfow8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The steps to preprocessing the data"
      ],
      "metadata": {
        "id": "f3Od3LWQkjBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the data is loaded in and we understand it's shape, it is time to understand preprocessing. Preprocessing a dataset refers to techniques and methods. The steps are:\n",
        "- Cleaning the data\n",
        "- handling missing values\n",
        "- transforming data for increased suitability for modelling\n",
        "- and either scaling or normalizing the data."
      ],
      "metadata": {
        "id": "GBbgyFBigzhM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning the data"
      ],
      "metadata": {
        "id": "pVMB1sUfhqjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use the dropna() method to remove any rows with null values. The resulting DataFrame with null values removed is stored in data_clean."
      ],
      "metadata": {
        "id": "a05e2CfajTiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with any null values\n",
        "data_clean = data.dropna()"
      ],
      "metadata": {
        "id": "9qtmP_sIfwGm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the drop_duplicates() method to get rid of any duplicate rows from the dataframe"
      ],
      "metadata": {
        "id": "AN3IPAIqlEEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop duplicates\n",
        "data_clean = data.drop_duplicates()"
      ],
      "metadata": {
        "id": "_gfAEzREjfN6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9mkyAN9lDSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}